---
title: |
  <center> HarvardX PH125.9x Data Science: Capstone Project II </center>
  <center> Applying Machine Learning Techniques to the SexLab Dataset </center>
author: "Luke Holmes Ph.D., University of Essex"
date: '2022-11-06'
output: pdf_document
---

```{r setup, include=FALSE}
# performs initial setup, installs and initialises required packages
knitr::opts_chunk$set(echo = TRUE)
if(!require(tidyverse)) install.packages("tidyverse",
                                         repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret",
                                     repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table",
                                          repos = "http://cran.us.r-project.org")
if(!require(dslabs)) install.packages("dslabs",
                                      repos = "http://cran.us.r-project.org")
if(!require(gridExtra)) install.packages("gridExtra",
                                      repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart",
                                         repos = "http://cran.us.r-project.org")
if(!require(Hmisc)) install.packages("Hmisc",
                                     repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("rpart.plot",
                                     repos = "http://cran.us.r-project.org")
library(rpart)
library(tidyverse)
library(caret)
library(data.table)
library(dslabs)
library(gridExtra)
library(rpart)
library(Hmisc)
library(rpart.plot)
```

# Introduction

## Background

Experimental Psychology has been formally exploring the topic of sexual orientation since the Kinsey Institute was founded in 1947. Often, the approach to conducting these experiments is that participants are asked to self-report their sexual orientation, and then various measures are taken from them - for example, how masculine or feminine they consider themselves compared to others of the same sex, or how they respond to videos of attractive people. 

When analysing this data, the approach often taken is to use the self-reported sexual orientation as the predictor, and examine its correlation with the other measures. However, we could also approach this differently, by attempting to predict sexual orientation using the other variables. Approaching the problem "backwards" in this manner allows us to use multiple predictors in our predictive models, and thus fine-tune our predictions to explain as much of the variance in sexual orientation as possible. 

## Dataset

The current dataset is real data gathered in the Human Sexuality Laboratory in the Department of Psychology at the University of Essex over the course of several years. It contains anonymised data from 279 male participants who visited the laboratory in person during this time. Each participant self-reported their sexual orientation, then took part in various tasks, during which data was gathered. Specific information on the variables is given in the Method section.  

## Project Goal

The current project is the second capstone coursework project for the HarvardX PH125.9x Data Science course. Our goal is to predict sexual orientation using several different kinds of models: Firstly, Linear Regression, which was the model used to analyse this data when it was first gathered. This is not a "true" Machine Learning algorithm, but it is included for the same of completeness and as a learning exercise for R. Secondly we will use K-Nearest Neighbours, a supervised learning algorithm which makes predictions based on "distance" between data points. Finally, we will use a Classification Tree, another kind of model which repeatedly partitions data in order to make predictions about the outcome variable based on the other variables.

## Key Steps

- **Introduction**: Background, dataset and project goals will be explained.
- **Methods**: All variables will be explained, and the dataset will be explored using summary statistics and visualisations.
- **Modelling**: A series of Machine Learning Models will be trained and tested on the data: Linear Regression, K-Nearest Neighbours and Classification Trees will be used.
- **Conclusions**: The models will be compared with one another, and the conclusions which can be drawn from the models will be explained.

# Methods

## Obtaining the Dataset

The dataset must first be downloaded, some column types changed, and the columns renamed appropriately. 

```{r download, echo=TRUE}
# Downloads and loads the sexlab dataset from my github repository
sexlabdata <- read.csv(
  "https://raw.githubusercontent.com/LukeH91/SexLabProject/main/sexlab-r-datasheet.csv", 
                      head=TRUE, sep=",",encoding="utf-8")


# changes the column names to more R-friendly ones
colnames(sexlabdata) <- c("id", "sexual_orientation", "pupil_dilation",
                          "subjective_ratings", "self_reported_gnc", "observer_rated_gnc")

# convert two columns from character to numeric for analyses
sexlabdata$pupil_dilation <- as.numeric(sexlabdata$pupil_dilation)
sexlabdata$subjective_ratings <- as.numeric(sexlabdata$subjective_ratings)

```

## Data Exploration

We will first look at the variables available in our data set.

```{r column-names, echo=FALSE}
# print all column names:
cat("Column Names: ",names(sexlabdata[1:3]))
names(sexlabdata[4:6])
```

In order, we have:

- **ID**: A unique ID given to each participant. This is only used to verify that no-one ends up in both the training and test sets.
- **Sexual Orientation**: A participant's sexual orientation, measured on a 7-point Kinsey scale from 0 (exclusively straight), through 3 (bisexual with no preference) to 6 (exclusively gay). For verification purposes, participants were also asked about their sexual attraction on a similar scale, and the two scores were averaged to give this composite score. Hence, some participants have a sexual orientation score ending in .5.
- **Pupil Dilation (PD)**: Participants were shown a series of videos featuring attractive men and women, and their pupil dilation was measured as they watched. In theory, pupils dilate when an individual is watching a video of someone they find attractive. The average dilation value while watching women was then deducted from the dilation value when watching men. Thus, a participant with a negative pupil dilation score responded more strongly to women, and a participant with a positive pupil dilation score responded more strongly to men. 
- **Subjective Ratings (SR)**: Participants were also asked to give ratings of how attractive they found the people in the videos on a scale from 0-6. Again, scores for videos featuring women were deducted from scores for videos featuring men. Thus, a participant with a negative score preferred women, and a participant with a positive score preferred men.  
- **Self-Reported Gender Nonconformity (SRG)**: Participants were asked how feminine they feel compared to other men of their same age, on a scale from 0-6. Lower scores indicated that participants felt less feminine, and higher scores indicated that they felt more feminine.
- **Observer-Rated Gender Nonconformity (ORG)**: Participants were briefly interviewed, and the video clips of these interviews were rated by neutral observers for how masculine or feminine the participant appeared in their speech, dress, and mannerisms on a scale from 0-6. Lower scores indicated that participants appeared more masculine, and higher scores indicated that they appeared more feminine. 

All of these variables can be theorised to have a relationship with sexual orientation - in general, research indicates that gay men are more feminine (on average) in their behaviours and mannerisms than straight men, and we can reasonably expect that they would respond more strongly to videos featuring men than videos featuring women. Thus, we should be able to predict a participant's sexual orientation from these variables with acceptable accuracy. 

## Data Visualisation

We will first verify that our dataset has the 279 participants that we expect it to have:

```{r rownums, echo=FALSE}
# print number of rows:
cat("Number of Participants:",dim(sexlabdata)[1])
```

We can now take a look at the distribution of their sexual orientations. As stated previously, since the sexual orientation variable is the average of two similar questions, we expect to see some participants who have orientations ending in a decimal:

```{r orientation-hist, echo=FALSE}
# histogram of distribution of sexual orientations
sexlabdata %>%
  ggplot(aes(x=sexual_orientation)) + 
  stat_bin(binwidth=0.5,color="black",fill="darkgreen") +
  scale_x_continuous(breaks=0:7) +
  ggtitle("Distribution of Sexual Orientations in the Sample") +
  xlab("Sexual Orientation") + 
  ylab("Number of Men")
```

From this, we can see that there are a significantly higher number of exclusively straight and exclusively gay participants. This is partly due to these specific groups being the focus of several of the research projects which resulted in this data. This will be less of a problem later, since we will group participants categorically into bins based on their sexual orientation, and bisexuals have a wider bin than either straight or gay men.

We will now examine the relationship between sexual orientation and the four predictive variables: Pupil Dilation, Subjective Ratings, Self-Reported Gender Nonconformity, and Observer-Rated Gender Nonconformity. In all cases, these graphs can be interpreted in the same way - sexual orientation is on the x axis, with straight men (0-1) on the left, bisexual men (2-4) in the middle, and gay men (5-6) on the right.

```{r linear-graphs, echo=FALSE, message = FALSE, warning = FALSE}
# array of four graphs showing the linear relationship between SO and the predictive variables
# trend line showing the relationship between sexual orientation and pupil dilation
plot_pd <- sexlabdata %>% ggplot(aes(sexual_orientation, pupil_dilation)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkred",method="lm") + 
  ggtitle("SO x Pupil Dilation") +
  xlab("Sexual Orientation") +
  ylab("Pupil Dilation")
# trend line showing the relationship between sexual orientation and subjective ratings
plot_sr <- sexlabdata %>% ggplot(aes(sexual_orientation, subjective_ratings)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkblue",method="lm") + 
  ggtitle("SO x Subjective Ratings") +
  xlab("Sexual Orientation") +
  ylab("Subjective Ratings")
plot_sgnc <- sexlabdata %>% ggplot(aes(sexual_orientation, self_reported_gnc)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkgreen",method="lm") + 
  ggtitle("SO x Self-Reported GNC") +
  xlab("Sexual Orientation") +
  ylab("Self-Reported GNC")
# trend line showing the relationship between sexual orientation and observer-rated GNC
plot_ognc <- sexlabdata %>% ggplot(aes(sexual_orientation, observer_rated_gnc)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="green",method="lm") + 
  ggtitle("SO x Observer-Rated GNC") +
  xlab("Sexual Orientation") +
  ylab("Observer-Rated GNC")
grid.arrange(plot_pd,plot_sr,plot_sgnc,plot_ognc)
```

As we can see here, all four of the variables have a positive relationship with sexual orientation as predicted. In other words, compared to straight men, gay men tend to respond more strongly to videos featuring men (both in pupil dilation and in their subjective ratings), and gay men tend to be more feminine than straight men, both in self-reports and observer ratings. Yet, these linear fit lines may not be the best way to depict the relationships between the variables - we will also try non-linear fits. 

```{r non-linear graphs, echo=FALSE, message = FALSE, warning = FALSE}
# array of the same four graphs, this time with non-linear fit lines
nlplot_pd <- sexlabdata %>% ggplot(aes(sexual_orientation, pupil_dilation)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkred") + 
  ggtitle("SO x Pupil Dilation") +
  xlab("Sexual Orientation") +
  ylab("Pupil Dilation")
nlplot_sr <- sexlabdata %>% ggplot(aes(sexual_orientation, subjective_ratings)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkblue") + 
  ggtitle("SO x Subjective Ratings") +
  xlab("Sexual Orientation") +
  ylab("Subjective Ratings")
nlplot_sgnc <- sexlabdata %>% ggplot(aes(sexual_orientation, self_reported_gnc)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="darkgreen") + 
  ggtitle("SO x Self-Reported GNC") +
  xlab("Sexual Orientation") +
  ylab("Self-Reported GNC")
nlplot_ognc <- sexlabdata %>% ggplot(aes(sexual_orientation, observer_rated_gnc)) +
  geom_point(position=position_jitter(w=0.15,h=0)) +
  scale_x_continuous(breaks=0:7) +
  geom_smooth(color="green") + 
  ggtitle("SO x Observer-Rated GNC") +
  xlab("Sexual Orientation") +
  ylab("Observer-Rated GNC")
grid.arrange(nlplot_pd,nlplot_sr,nlplot_sgnc,nlplot_ognc)
```

As we can see here, in some cases, the relationship between the predictive variables and sexual orientation appears to be better-represented using a non-linear model. These effects seem to be primarily driven by bisexual men, who are closer to straight men on some measures (e.g. pupil dilation) and closer to gay men on others (e.g. subjective ratings).

To be sure of the exact nature of the relationships between sexual orientation and the predictors, we will calculate the Pearson correlations (r) and corresponding significance values (p) for each pairwise comparison. 

```{r correlations, echo=FALSE}
# create set of pearson correlations, p values and Ns for all columns
correlations <- rcorr(as.matrix(sexlabdata),type="spearman")
# save each set as its own data frame
r <- data.frame(correlations[1])
p <- data.frame(correlations[3])
n <- data.frame(correlations[2])
# combine relevant numbers from each one into a table
# create data frame to show all relevant values easily
corrtable <- data.frame(c("r", "p"),
                        c(r[3,2],p[3,2]),
                        c(r[4,2],p[4,2]),
                        c(r[5,2],p[5,2]),
                        c(r[6,2],p[6,2]))
colnames(corrtable) <- c("", "Pupil Dilation","Subjective Ratings",
                         "Self-Reported GNC","Observer-Rated GNC")
# round all numbers in data frame to 3 decimal places
is.num <- sapply(corrtable, is.numeric)
corrtable[is.num] <- lapply(corrtable[is.num], round, 3)
# print data frame
print(corrtable)
```

The above table gives us two interesting insights: Firstly, every predictive variable is correlated with sexual orientation. All four p-values were below .05, indicating that these are statistically significant relationships. Secondly, although the variables are all correlated (and in the same direction, positively) with sexual orientation, the magnitude of these correlations differs, and the two gender nonconformity variables have a weaker relationship with sexual orientation than pupil dilation or subjective ratings.  

## Insights and Model Building

Exploring and visualising the data has given us several valuable insights which we must take into account when building our models. In summary, they are:

1. There are more exclusively gay and exclusively straight men in our sample than bisexual men. This is (somewhat) acceptable for linear regression, but would be problematic for other kinds of continuous modelling. We will thus need to group participants by sexual orientation and use classification modelling techniques for our other models. 
2. The relationship between sexual orientation and the other variables may be non-linear. Thus, it makes sense to explore options other than linear regression when trying to make predictions based on these variables. 
3. All four predictive variables were significantly correlated with sexual orientation. However, their magnitudes differed - the relationship between sexual orientation, pupil dilation and subjective ratings was stronger than the relationship between sexual orientation and either of the gender nonconformity variables. This may mean that the latter two variables are less suitable for use in predicting sexual orientation. 

# Modelling

With the information we have gathered from examining the data set, we will now build a series of models, with the aim of predicting sexual orientation. The first set of 4 models will be simple Linear Regression models, and this will be followed by a set of 4 K-Nearest Neighbour models and 4 Classification Tree models, for a total of 12 models. 

For all three sets of models, we will add predictors stage-by-stage in descending order of their correlation with sexual orientation; thus, in each set of models, the order will be:

1. Sexual Orientation predicted by **Pupil Dilation**
2. Sexual Orientation predicted by **Pupil Dilation and Subjective Ratings**
3. Sexual Orientation predicted by **Pupil Dilation, Subjective Ratings, and Self-Reported Gender Nonconformity**
4. Sexual Orientation predicted by **Pupil Dilation, Subjective Ratings, Self-Reported Gender Nonconformity and Observer-Rated Gender Nonconformity**

At the end of each section, we will add the relevant figures for measuring the effectiveness of the models (R-Squared in the case of Linear Regression and Accuracy in the case of KNN and CT) to a table for easy comparison.

The dataset must first be split into training and testing sets. The code for doing this is below. All models will first be trained on the training set, and then will be used to predict the sexual orientation of participants in the testing set. Owing to the size of the data set (which is very large for this kind of Psychology research, but relatively small by Machine Learning standards), we decided on a train/test split of 80/20, to avoid either set being too small to function properly. 

```{r lr-traintest, echo=TRUE, warning=FALSE, results = FALSE}
# sets seed
set.seed(1, sample.kind = "Rounding")
# split the data into training and test sets
test_index <- createDataPartition(y = sexlabdata$sexual_orientation, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- sexlabdata[-test_index,]
test_set <- sexlabdata[test_index,]
# verify that the same id does not appear in both sets
train_set$id %in% test_set$id
```

## Model Set 1: Linear Regression

We will first attempt to predict the sexual orientation of the test set using a series of Linear Regression models. 

```{r set1, echo=TRUE, warning=FALSE}
# variables will be added to the model in descending order of predictive power
# LR model 1: PD
# model is fitted using the training set
fit1 <- lm(sexual_orientation ~ pupil_dilation, data = train_set)
# predictions are generated on the test set
y_hat1 <- predict(fit1,newdata=test_set)
# summary of model is shown
summary(fit1)

# LR model 2: PD/SR
# model is fitted using the training set
fit2 <- lm(sexual_orientation ~ pupil_dilation + subjective_ratings, data = train_set)
# predictions are generated on the test set
y_hat2 <- predict(fit2,newdata=test_set)
# summary of model is shown
summary(fit2)

# LR model 3: PD/SR/SRG
# model is fitted using the training set
fit3 <- lm(sexual_orientation ~ pupil_dilation + subjective_ratings +
             self_reported_gnc, data = train_set)
# predictions are generated on the test set
y_hat3 <- predict(fit3,newdata=test_set)
# summary of model is shown
summary(fit3)

# LR model 4: PD/SR/SRG/ORG
# model is fitted using the training set
fit4 <- lm(sexual_orientation ~ pupil_dilation + subjective_ratings +
             self_reported_gnc + observer_rated_gnc, data = train_set)
# predictions are generated on the test set
y_hat4 <- predict(fit4,newdata=test_set)
# summary of model is shown
summary(fit4)
```

Our results table so far looks like this:

```{r model1table, echo=FALSE}
# create results table, add 4 linear regression R^2 values to it
resultstable <- data.frame(c("PD", "PD/SR", "PD/SR/SRG", "PD/SR/SRG/ORG"),
                           c("0.1391","0.2369","0.2344","0.2327"),
                           c("","","",""),
                           c("","","",""))
colnames(resultstable) <- c("Model", "LR (R^2)","KNN (Acc)","Class (Acc)")
# print results table so far
print(resultstable)
```

As we can see, the Adjusted R-Squared value - a measure of how much of the total variance in sexual orientation is explained by the model - improves significantly in model 2, when subjective ratings are added as a predictor. However, following that, the addition of either of the gender nonconformity variables does not improve the predictive power of the model further; rather, it causes it to decrease slightly. 

This is possibly due to colinearity between the variables, or because their predictive power over sexual orientation is weaker than the first two variables to begin with. The results of the models themselves back this up - in model 4, we can clearly see that although PD and SR are significantly related to sexual orientation, SRG and ORG are not. In other words, the variance in sexual orientation that they account for is better explained by PD and SR, and the relationship between SRG/ORG and sexual orientation vanishes when PD and SR are controlled for in a model like this. 

## Model Set 2: K-Nearest Neighbours

As mentioned previously, the distribution of sexual orientations in our sample is not even - there are more exclusively gay and straight men in the sample than bisexual men. This is largely due to the priorities of the research projects which make up this dataset. This presents a problem for models which treat sexual orientation as a continuous variable. 

As such, we will take a different approach - our second and third set of models will be based on classification, and we will convert sexual orientation into a factor to accommodate this. Specifically, we will categorise participants from 0.0 to 1.0 as "straight", 1.5 to 4.5 as "bi", and 5.0 to 6.0 as "gay". We must also split this new dataset into train and test sets.  

```{r classdata, echo=TRUE, warning=FALSE, results = FALSE}
# create categorical sexual orientation variable through binning
knndata <- sexlabdata %>% 
  mutate(so_category=ifelse(sexual_orientation %in% c(0.0, 0.5, 1.0), "straight",
                     ifelse(sexual_orientation %in% c(1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5),
                                                      "bi", "gay")))
# turn this new categorical variable into a factor
knndata$so_category <- as.factor(knndata$so_category)
# drop the old sexual orientation variable to prevent it being used for predictions
knndata <- select(knndata,-sexual_orientation)
# drop id variable for the same reason
knndata <- select(knndata,-id)
# sets seed
set.seed(1, sample.kind = "Rounding")
# split the new dataset into training and test sets
test_index <- createDataPartition(y = knndata$so_category, times = 1,
                                  p = 0.2, list = FALSE)
knn_train_set <- knndata[-test_index,]
knn_test_set <- knndata[test_index,]
# sets parameters for cross-validation of knn models
trctrl <- trainControl(method = "repeatedcv", number = 20, repeats = 5)
```

The slightly larger bin size given to bisexual participants helps correct the problem of uneven sample distribution, although it is still not balanced:

```{r groups, echo=FALSE}
# examine distribution of groups
summary(knndata$so_category)
```

Although not ideal, this is adequate for training classification models. We will again compute four models - this time K-nearest Neighbour models - and each time we will add a new predictor and measure the effectiveness of the model. Since this is a classification model, we will now be measuring the effectiveness of its predictions using Accuracy. At each stage, the optimal K will be found through cross-validation with 20 folds repeated 5 times. All variables were centered and scaled (standardised) before predictions were made. 

```{r set2, echo=TRUE}
# KNN model 1: PD
# knn model is fitted
knn_fit1 <- train(so_category ~pupil_dilation, 
                  data = knn_train_set, method = "knn", trControl=trctrl,
                  preProcess = c("center", "scale"), tuneLength = 10)
# shows accuracy of knn model in cross-validation
knn_fit1
# use trained model to predict test set
test_pred1 <- predict(knn_fit1, newdata = knn_test_set)
# confusion matrix showing the results
knncf1 <- confusionMatrix(test_pred1, knn_test_set$so_category)

# KNN model 2: PD/SR
# knn model is fitted
knn_fit2 <- train(so_category ~pupil_dilation + subjective_ratings, 
                 data = knn_train_set, method = "knn", trControl=trctrl,
                 preProcess = c("center", "scale"), tuneLength = 10)
# shows accuracy of knn model in cross-validation
knn_fit2
# use trained model to predict test set
test_pred2 <- predict(knn_fit2, newdata = knn_test_set)
# confusion matrix showing the results
knncf2 <- confusionMatrix(test_pred2, knn_test_set$so_category)


# KNN model 3: PD/SR/SRG
# knn model is fitted
knn_fit3 <- train(so_category ~pupil_dilation + subjective_ratings + self_reported_gnc, 
                 data = knn_train_set, method = "knn", trControl=trctrl,
                 preProcess = c("center", "scale"), tuneLength = 10)
# shows accuracy of knn model in cross-validation
knn_fit3
# use trained model to predict test set
test_pred3 <- predict(knn_fit3, newdata = knn_test_set)
# confusion matrix showing the results
knncf3 <- confusionMatrix(test_pred3, knn_test_set$so_category)

# knn model 4: PD/SR/SRG/ORG
# knn model is fitted
knn_fit4 <- train(so_category ~., data = knn_train_set, method = "knn",
                 trControl=trctrl,
                 preProcess = c("center", "scale"),
                 tuneLength = 10)
# shows accuracy of knn model in cross-validation
knn_fit4
# use trained model to predict test set
test_pred4 <- predict(knn_fit4, newdata = knn_test_set)
# confusion matrix showing the results
knncf4 <- confusionMatrix(test_pred4, knn_test_set$so_category)
```

The results of testing these models on the testing set are shown below:

```{r model2table, echo=FALSE}
# add KNN models to results table
resultstable <- data.frame(c("PD", "PD/SR", "PD/SR/SRG", "PD/SR/SRG/ORG"),
                           c("0.1391","0.2369","0.2344","0.2327"),
                           c(knncf1$overall["Accuracy"], knncf2$overall["Accuracy"],
                             knncf3$overall["Accuracy"], knncf4$overall["Accuracy"]),
                           c("","","",""))
colnames(resultstable) <- c("Model", "LR (R^2)","KNN (Acc)","Class (Acc)")
# print results table so far
print(resultstable)
```

Here we see a broadly similar pattern to the one we found using Linear Regression: It is not the case that simply adding more variables makes the model more accurate. Instead, the most accurate model is #2 (PD & SR), and adding the gender nonconformity variables actually reduces the overall accuracy of the model. 

## Model Set 3: Classification Trees

Finally, we will repeat the same set of four models, but this time using a Classification Tree method. Again, sexual orientation will be treated as a factor rather than a continuous variable. The models will be trained on the training set, and we will use their Accuracy in predicting the sexual orietation of the test set as a measure of the success of the model. 

```{r set3, echo=TRUE}
# Classification model 1: PD
# classification model is fitted and plotted
rpartfit1 <- rpart(so_category~pupil_dilation, data = knn_train_set, method = 'class')
rpart.plot(rpartfit1)
# fitted model used to predict test set
classpredict1 <- predict(rpartfit1,newdata=knn_test_set, type ="class")
# confusion matrix created and printed
classcf1 <- confusionMatrix(classpredict1, knn_test_set$so_category)
classcf1

# Classification model 2: PD/SR
# classification model is fitted and plotted
rpartfit2 <- rpart(so_category~pupil_dilation+subjective_ratings,
                   data = knn_train_set, method = 'class')
rpart.plot(rpartfit2)
# fitted model used to predict test set
classpredict2 <- predict(rpartfit2,newdata=knn_test_set, type ="class")
# confusion matrix created and printed
classcf2 <- confusionMatrix(classpredict2, knn_test_set$so_category)
classcf2

# Classification model 3: PD/SR/SRG
# classification model is fitted
rpartfit3 <- rpart(so_category~pupil_dilation+subjective_ratings+
                     self_reported_gnc, data = knn_train_set, method = 'class')
rpart.plot(rpartfit3)
# fitted model used to predict test set
classpredict3 <- predict(rpartfit3,newdata=knn_test_set, type ="class")
# confusion matrix created and printed
classcf3 <- confusionMatrix(classpredict3, knn_test_set$so_category)
classcf3

# Classification model 4: PD/SR/SRG/ORG
# classification model is fitted
rpartfit4 <- rpart(so_category~., data = knn_train_set, method = 'class')
rpart.plot(rpartfit4)
# fitted model used to predict test set
classpredict4 <- predict(rpartfit4,newdata=knn_test_set, type ="class")
classcf4 <- confusionMatrix(classpredict4, knn_test_set$so_category)
# confusion matrix created and printed
classcf4
```

The results of testing these models on the testing set are shown below

```{r model3table, echo=FALSE}
# add classification models to results table
resultstable <- data.frame(c("PD", "PD/SR", "PD/SR/SRG", "PD/SR/SRG/ORG"),
                           c("0.1391","0.2369","0.2344","0.2327"),
                           c(knncf1$overall["Accuracy"], knncf2$overall["Accuracy"],
                             knncf3$overall["Accuracy"], knncf4$overall["Accuracy"]),
                           c(classcf1$overall["Accuracy"],classcf2$overall["Accuracy"],
                             classcf4$overall["Accuracy"],classcf4$overall["Accuracy"]))
colnames(resultstable) <- c("Model", "LR (R^2)","KNN (Acc)","Class (Acc)")
# print final results table
print(resultstable)
```

We see a similar pattern as before: Adding more predictors does not necessarily increase the accuracy of the model. Rather, the most accurate model is the first one, with only pupil dilation as a predictor, and the accuracy decreases each time a new predictor is added. 

# Conclusions

In summary, we found that adding more variables does not necessarily improve the fit of a model. This applied to both the Linear Regression models and also the factor-based classification models. Broadly, the models followed the same pattern: Pupil dilation, which had the strongest correlation with sexual orientation, was always a very strong predictor, and subjective ratings, with the second-strongest correlation, usually improved the model by being added. However, the two gender nonconformity variables tended to reduce the predictive power of a model when taken into consideration. It is possible that this is because they are correlated with one another, or correlate with the other predictors, and thus are unable to explain any additional variance when added to a model in stages 3 and 4. Another potential explanation is that their relationship with sexual orientation, although statistically significant, was simply weaker than the relationship between sexual orientation and the other two predictors, and thus they were less predictive.

```{r finaltable, echo=FALSE}
# add classification models to results table
print("Final Results Table:")
resultstable <- data.frame(c("PD", "PD/SR", "PD/SR/SRG", "PD/SR/SRG/ORG"),
                           c("0.1391","0.2369","0.2344","0.2327"),
                           c(knncf1$overall["Accuracy"], knncf2$overall["Accuracy"],
                             knncf3$overall["Accuracy"], knncf4$overall["Accuracy"]),
                           c(classcf1$overall["Accuracy"],classcf2$overall["Accuracy"],
                             classcf4$overall["Accuracy"],classcf4$overall["Accuracy"]))
colnames(resultstable) <- c("Model", "LR (R^2)","KNN (Acc)","Class (Acc)")
# print final results table
print(resultstable)
```

One clear limitation of this project is the sample size. Gathering data such as this is expensive and labour-intensive, and although the sample is large by the standards of research done in this area, it is still small by the standards of most Machine Learning models. Although our best efforts were made to mitigate this factor - for example, through the use of carefully-selected train/test splits and binning, we cannot rule out that issues of sample size or distribution may have affected the findings. 

Future research could approach this problem with an even wider range of different predictive models. If a more evenly-distributed sample was recruited, these could include continuous Machine Learning models, and this may shed more light on the issue of why certain predictors did not seem to benefit the models. Additionally, it would be worth focusing not just on Accuracy, but also on Sensitivity and Specificity. Exploring these parameters in addition to the ones already present was outside of the scope of this paper, but it is possible that a clearer picture of what is going on in these models may be gleaned from examining these alongside Accuracy.